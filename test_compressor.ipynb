{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import logging\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from CompressionLibrary.reinforcement_models import DuelingDQNAgentBigger as DuelingDQNAgent\n",
    "from CompressionLibrary.reward_functions import reward_MnasNet as calculate_reward\n",
    "from CompressionLibrary.environments import ModelCompressionSVDIntEnv\n",
    "from CompressionLibrary.utils import calculate_model_weights\n",
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from scipy.spatial import distance_matrix\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LeNet_DDQN_discrete_tuning_zero_rw_FM_best_img_fashion_mnist-kmnist', 'LeNet_DDQN_discrete_tuning_zero_rw_FM_best_img_fashion_mnist-mnist', 'LeNet_DDQN_discrete_tuning_zero_rw_FM_best_img_kmnist-mnist']\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# 'fashion_mnist','kmnist', 'mnist', , 'fashion_mnist-kmnist-mnist'\n",
    "agents_names = list(map(lambda x: 'LeNet_DDQN_discrete_tuning_zero_rw_FM_best_img_'+x, ['fashion_mnist-kmnist', 'fashion_mnist-mnist','kmnist-mnist']))\n",
    "dataset_names = ['fashion_mnist','kmnist', 'mnist']\n",
    "run_id = datetime.now().strftime('%Y-%m-%d-%H-%M%S-') + str(uuid4())\n",
    "\n",
    "print(agents_names)\n",
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "data_path = \"./data/\"\n",
    "\n",
    "log_name = 'DDQN_SVD10_test_agents'\n",
    "test_filename = data_path + 'stats/DDQN_SVD10_{}_tests'.format(log_name)\n",
    "\n",
    "agents_path = data_path+'agents/DDQN/checkpoints/'\n",
    "\n",
    "if strategy:\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, handlers=[\n",
    "    logging.FileHandler(data_path + f'logs/{log_name}.log', 'w+')],\n",
    "    format='%(asctime)s -%(levelname)s - %(funcName)s -  %(message)s')\n",
    "logging.root.setLevel(logging.DEBUG)\n",
    "\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.ERROR)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Parameters shared in training and testing env\n",
    "current_state = 'layer_input'\n",
    "next_state = 'layer_output'\n",
    "tuning_epochs = 0\n",
    "tuning_mode = 'final'\n",
    "\n",
    "batch_size_per_replica = 128\n",
    "tuning_batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "# Env variables\n",
    "training_state_set_source = 'test_all'\n",
    "training_num_feature_maps = -1\n",
    "reward_step = True\n",
    "\n",
    "\n",
    "# Testing variables\n",
    "testing_state_set_source = 'test_best'\n",
    "testing_num_feature_maps = -1\n",
    "eval_n_samples = 1\n",
    "\n",
    "#Autoencoder\n",
    "latent_dim = 64\n",
    "\n",
    "verbose = 0\n",
    "\n",
    "epsilon_start_value = 1.0\n",
    "\n",
    "\n",
    "\n",
    "layer_name_list = ['conv2d_1',  'dense', 'dense_1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation and data loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000    14    14    16] (10000, 400)\n",
      "The action space is [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n"
     ]
    }
   ],
   "source": [
    "def create_model(dataset_name, train_ds, valid_ds):\n",
    "    checkpoint_path = f\"./data/models/lenet_{dataset_name}/cp.ckpt\"\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    train_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    input = tf.keras.layers.Input((28,28,1))\n",
    "    x = tf.keras.layers.Conv2D(6, (5,5), padding='SAME', activation='sigmoid', name='conv2d')(input)\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), strides=2, name='avg_pool_1')(x)\n",
    "    x = tf.keras.layers.Conv2D(16, (5,5), padding='VALID', activation='sigmoid', name='conv2d_1')(x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), strides=2, name='avg_pool_2')(x)\n",
    "    x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "    x = tf.keras.layers.Dense(120, activation='sigmoid', name='dense')(x)\n",
    "    x = tf.keras.layers.Dense(84, activation='sigmoid', name='dense_1')(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    model = tf.keras.Model(input, x, name='LeNet')\n",
    "    model.compile(optimizer=optimizer, loss=loss_object,\n",
    "                    metrics=[train_metric])\n",
    "\n",
    "    try:\n",
    "        model.load_weights(checkpoint_path).expect_partial()\n",
    "    except:\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "        model.fit(train_ds,\n",
    "          epochs=3000,\n",
    "          validation_data=valid_ds,\n",
    "          callbacks=[cp_callback])\n",
    "\n",
    "    return model             \n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(784, activation='sigmoid'),\n",
    "      layers.Reshape((28, 28))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def dataset_preprocessing_img2img(img, label):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = img/255.0\n",
    "    return img, img\n",
    "\n",
    "def dataset_preprocessing_img2label(img, label):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = img/255.0\n",
    "    return img, label\n",
    "\n",
    "def load_dataset(dataset_name, dataset_preprocessing, batch_size=128):\n",
    "    splits, info = tfds.load(dataset_name, as_supervised=True, with_info=True, shuffle_files=True,\n",
    "                                split=['train[:80%]', 'train[80%:]','test'])\n",
    "\n",
    "    (train_examples, validation_examples, test_examples) = splits\n",
    "    num_examples = info.splits['train'].num_examples\n",
    "\n",
    "    num_classes = info.features['label'].num_classes\n",
    "    input_shape = info.features['image'].shape\n",
    "\n",
    "    input_shape = (28,28,1)\n",
    "\n",
    "    train_ds = train_examples.map(dataset_preprocessing, num_parallel_calls=tf.data.AUTOTUNE).cache().shuffle(buffer_size=1000, reshuffle_each_iteration=True).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    valid_ds = validation_examples.map(dataset_preprocessing, num_parallel_calls=tf.data.AUTOTUNE).cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = test_examples.map(dataset_preprocessing, num_parallel_calls=tf.data.AUTOTUNE).cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_ds, valid_ds, test_ds, input_shape, num_classes\n",
    "\n",
    "\n",
    "\n",
    "def get_best_per_class(tf_dataset, autoencoder):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for x,y in tfds.as_numpy(tf_dataset):\n",
    "        x_train.append(x)\n",
    "        y_train.append(y)\n",
    "\n",
    "    x_train = np.concatenate(x_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "    encoded_imgs = autoencoder.encoder(x_train).numpy()\n",
    "    decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
    "    clf = NearestCentroid()\n",
    "    clf.fit(encoded_imgs, y_train)\n",
    "\n",
    "    best_images = []\n",
    "    best_decoded = []\n",
    "    labels_best = []\n",
    "    num_classes = clf.centroids_.shape[0]\n",
    "    for class_number in range(num_classes):\n",
    "        class_members = np.argwhere(y_train == class_number).flatten()\n",
    "        dm = distance_matrix(encoded_imgs[class_members], clf.centroids_)\n",
    "        idx_best = np.argmin(dm[:, class_number])\n",
    "        best_images.append(x_train[class_members[idx_best]])\n",
    "        best_decoded.append(decoded_imgs[class_members[idx_best]])\n",
    "        labels_best.append(y_train[[class_members[idx_best]]])\n",
    "        logger.debug(f'Best member of {class_number} is {class_members[idx_best]} with class {labels_best[-1]}')\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((best_images, labels_best)).batch(num_classes)\n",
    "\n",
    "def generate_dataset_best_img(dataset_name, latent_dim, batch_size):\n",
    "    autoencoder = Autoencoder(latent_dim)\n",
    "    autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "    train_ds, valid_ds, test_ds, input_shape, _ = load_dataset(dataset_name, dataset_preprocessing_img2img, batch_size)\n",
    "    autoencoder.fit(train_ds,\n",
    "                    epochs=50,\n",
    "                    shuffle=True,\n",
    "                    validation_data=valid_ds, verbose=0)\n",
    "\n",
    "    ft_train_ds, ft_valid_ds, ft_test_ds, input_shape, num_classes = load_dataset(dataset_name, dataset_preprocessing_img2label, batch_size)\n",
    "\n",
    "    train_state_ds = get_best_per_class(ft_train_ds, autoencoder)\n",
    "    valid_state_ds = get_best_per_class(ft_valid_ds, autoencoder)\n",
    "    test_state_ds = get_best_per_class(ft_test_ds, autoencoder)\n",
    "\n",
    "\n",
    "\n",
    "    return train_state_ds, valid_state_ds, test_state_ds, ft_train_ds, ft_valid_ds, ft_test_ds, input_shape, num_classes\n",
    "\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "def create_environments(dataset_names, num_feature_maps, state_set_source):\n",
    "    w_comprs = ['InsertDenseSVD'] \n",
    "    l_comprs = ['MLPCompression']\n",
    "    compressors_list = w_comprs +  l_comprs\n",
    "\n",
    "    parameters = {}\n",
    "    parameters['InsertDenseSVD'] = {'layer_name': None, 'percentage': None}\n",
    "    parameters['MLPCompression'] = {'layer_name': None, 'percentage': None}\n",
    "    environments = []\n",
    "    for dataset in dataset_names:\n",
    "        train_state_ds, valid_state_ds, test_state_ds, train_ds, valid_ds, test_ds, input_shape, num_classes = generate_dataset_best_img(dataset, latent_dim, tuning_batch_size)\n",
    "        if state_set_source=='test_all':\n",
    "            state_ds = test_ds\n",
    "        elif state_set_source == 'test_best':\n",
    "            state_ds = test_state_ds\n",
    "\n",
    "        new_func = partial(create_model, dataset_name=dataset, train_ds=train_ds, valid_ds=valid_ds)\n",
    "        env = ModelCompressionSVDIntEnv(\n",
    "                reward_func=calculate_reward,\n",
    "                compressors_list=compressors_list, \n",
    "                create_model_func=new_func, \n",
    "                compr_params=parameters, \n",
    "                train_ds=train_ds, \n",
    "                validation_ds=valid_ds, \n",
    "                test_ds=test_ds, \n",
    "                layer_name_list=layer_name_list, \n",
    "                input_shape=input_shape, \n",
    "                tuning_batch_size=tuning_batch_size, \n",
    "                tuning_epochs=tuning_epochs,\n",
    "                state_ds=state_ds, \n",
    "                current_state_source=current_state, \n",
    "                next_state_source=next_state, \n",
    "                num_feature_maps=num_feature_maps, \n",
    "                verbose=verbose,\n",
    "                tuning_mode=tuning_mode,\n",
    "                strategy=strategy)\n",
    "\n",
    "        environments.append(env)\n",
    "\n",
    "    return environments\n",
    "\n",
    "test_all_envs = create_environments(dataset_names,num_feature_maps=training_num_feature_maps, state_set_source=training_state_set_source)\n",
    "test_envs = create_environments(dataset_names,num_feature_maps=testing_num_feature_maps, state_set_source=testing_state_set_source)\n",
    "\n",
    "conv_shape, dense_shape = test_all_envs[0].observation_space()\n",
    "action_space = test_all_envs[0].action_space()\n",
    "num_actions = len(action_space)\n",
    "\n",
    "print(conv_shape, dense_shape)\n",
    "\n",
    "\n",
    "fc_n_actions = conv_n_actions = num_actions\n",
    "\n",
    "print(f'The action space is {action_space}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_record(conv_agent, fc_agent,env, conv_replay, fc_replay,run_id, test_number, dataset_name, save_name, n_games=10, exploration=True):\n",
    "    # initial state\n",
    "    s = env.reset()\n",
    "    # Play the game for n_steps as per instructions above\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    rewards = []\n",
    "    acc = []\n",
    "    weights = []\n",
    "    infos = []\n",
    "    total_time = 0\n",
    "\n",
    "    for it in range(n_games):\n",
    "        start = datetime.now()\n",
    "        last_conv_data = None\n",
    "        skip_add_replay = False\n",
    "        data = []\n",
    "        for k in range(1, len(env.original_layer_name_list)+1):\n",
    "            tf.keras.backend.clear_session()\n",
    "            # Get the current layer name\n",
    "            current_layer_name = env.original_layer_name_list[env._layer_counter]\n",
    "            # Get the layer.\n",
    "            layer = env.model.get_layer(current_layer_name)\n",
    "\n",
    "            if env._layer_counter+1<len(env.original_layer_name_list):\n",
    "                \n",
    "                # Get the next layer name\n",
    "                next_layer_name = env.original_layer_name_list[env._layer_counter+1]\n",
    "                # Get the layer.\n",
    "                next_layer = env.model.get_layer(next_layer_name)\n",
    "                if isinstance(layer, tf.keras.layers.Conv2D) and not isinstance(next_layer, tf.keras.layers.Conv2D):\n",
    "                    logger.debug('Last convolutional layer.')\n",
    "                    skip_add_replay = True\n",
    "                else:\n",
    "                    skip_add_replay = False\n",
    "\n",
    "            was_conv = True\n",
    "            # Choose agent depending on layer type.\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                # Calculate q values for batch of images\n",
    "                qvalues = conv_agent.get_qvalues(s)\n",
    "                action = conv_agent.sample_actions(qvalues.numpy(), exploration=exploration)[0]\n",
    "            if isinstance(layer, tf.keras.layers.Dense):\n",
    "                was_conv = False\n",
    "                s = np.squeeze(s)\n",
    "                temp = np.zeros(shape=(s.shape[0], 400))\n",
    "                temp[:, :s.shape[-1]] = s\n",
    "                s = temp\n",
    "                qvalues = fc_agent.get_qvalues(s)\n",
    "                action = fc_agent.sample_actions(qvalues.numpy(), exploration=exploration)[0]\n",
    "\n",
    "            # Action is the mode of the action.\n",
    "            \n",
    "            logger.debug(f'Action for layer {current_layer_name} layer is {action}')\n",
    "\n",
    "            # Apply action\n",
    "            new_s, r, done, info = env.step(action) \n",
    "            # r * = 100\n",
    "            \n",
    "\n",
    "            logger.debug(f'Iteration {it} - Layer {current_layer_name} {k}/{len(env.original_layer_name_list)}\\tChosen action {action} has {r} reward.')\n",
    "            logger.debug(info)\n",
    "\n",
    "            num_inst = s.shape[0]\n",
    "\n",
    "            # Use input of next layer instead of output of current for all states except final.\n",
    "            if not done:\n",
    "                new_s = env.get_state('current_state')\n",
    "\n",
    "            if exploration:\n",
    "                new_s = np.squeeze(new_s)\n",
    "                temp = np.zeros(shape=(new_s.shape[0], 400))\n",
    "                temp[:, :new_s.shape[-1]] = new_s\n",
    "                new_s = temp\n",
    "                data.append([s, action, r, new_s, done, was_conv])\n",
    "\n",
    "            \n",
    "            s = env.get_state('current_state')\n",
    "\n",
    "            if done:\n",
    "                if exploration:\n",
    "                    for row in data:\n",
    "                        # Replace r with _ for assigning the same reward to all actions of episode.\n",
    "                        s, a, rw, sn, done, conv = row\n",
    "                        actions_batch = np.array([a]*num_inst)\n",
    "                        done_float = 1.0 if done else 0.0\n",
    "                        num_inst = s.shape[0]\n",
    "                        if conv:\n",
    "                            logger.debug(f'Conv replay has {len(conv_replay)} examples.')\n",
    "                            td_errors = calculate_td_error_conv(s, actions_batch, [r]*num_inst, sn, done_float )\n",
    "                            td_errors = np.reshape(np.abs(td_errors), -1)\n",
    "                            conv_replay.add_multiple(s, [a]*num_inst, [r]*num_inst, sn, td_errors, [done]*num_inst, dataset_name)\n",
    "                            logger.debug(f'Conv replay has {len(conv_replay)} examples.')\n",
    "                        else:\n",
    "                            logger.debug(f'FC replay has {len(fc_replay)} examples.')\n",
    "                            td_errors = calculate_td_error_fc(s, actions_batch, [rw]*num_inst, sn, done_float )\n",
    "                            td_errors = np.reshape(np.abs(td_errors), -1)\n",
    "                            fc_replay.add_multiple(s, [a]*num_inst, [r]*num_inst, sn, td_errors, [done]*num_inst, dataset_name)\n",
    "                            logger.debug(f'FC replay has {len(fc_replay)} examples.')\n",
    "                        logging.debug(f'Layer TD error is {td_errors}')\n",
    "                s = env.reset()\n",
    "                break\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "        # Using 0f as actions are percentages without decimals.\n",
    "        info['actions'] = ','.join(['{:.0f}'.format(x) for x in info['actions']] )\n",
    "        info['run_id'] = run_id\n",
    "        info['test_number'] = test_number\n",
    "        info['game_id'] = it\n",
    "        info['dataset'] = dataset_name\n",
    "        del info['layer_name']\n",
    "        rewards.append(r)\n",
    "        acc.append(info['test_acc_after'])\n",
    "        weights.append(info['weights_after'])\n",
    "        new_row = pd.DataFrame(info, index=[0])\n",
    "        if not os.path.isfile(save_name):\n",
    "            new_row.to_csv(save_name, index=False)\n",
    "        else: # else it exists so append without writing the header\n",
    "            new_row.to_csv(save_name, mode='a', index=False, header=False)\n",
    "\n",
    "        # Correct reward is the last value of r.\n",
    "        \n",
    "        end = datetime.now()\n",
    "        time_diff = (end - start).total_seconds()\n",
    "        total_time += time_diff\n",
    "        logger.info(f'Took {time_diff} seconds for one compression.')\n",
    "\n",
    "    logger.info(f'Evaluation of {n_games} took {total_time} secs. An average of {total_time/n_games} secs per game.')\n",
    "\n",
    "    return np.mean(rewards), np.mean(acc), np.mean(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [01:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "fc_agent = DuelingDQNAgent(name=\"ddqn_agent_fc\", state_shape=dense_shape,\n",
    "                        n_actions=fc_n_actions, epsilon=epsilon_start_value, layer_type='fc')\n",
    "\n",
    "    \n",
    "conv_agent = DuelingDQNAgent(\n",
    "    name=\"ddqn_agent_conv\", state_shape=conv_shape, n_actions=conv_n_actions, epsilon=epsilon_start_value, layer_type='cnn')\n",
    "\n",
    "iterations = len(dataset_names) * len(agents_names)\n",
    "\n",
    "conv_exp_replay = None\n",
    "fc_exp_replay = None\n",
    "\n",
    "with tqdm(total=iterations) as t:\n",
    "    for idx, dataset_name in enumerate(dataset_names):\n",
    "        env_all = test_all_envs[idx]\n",
    "        env_best = test_envs[idx]\n",
    "\n",
    "        for agent_name in agents_names:\n",
    "            conv_agent.model.load_weights(agents_path+agent_name+'_conv.ckpt')\n",
    "            fc_agent.model.load_weights(agents_path+agent_name+'_fc.ckpt')\n",
    "\n",
    "            rw, acc, weights = play_and_record(conv_agent, fc_agent, env_all, conv_exp_replay, fc_exp_replay,run_id=run_id,test_number=agent_name, dataset_name=dataset_name,save_name=test_filename+'_all.csv', n_games=eval_n_samples, exploration=False)\n",
    "            rw, acc, weights = play_and_record(conv_agent, fc_agent, env_best, conv_exp_replay, fc_exp_replay,run_id=run_id,test_number=agent_name, dataset_name=dataset_name,save_name=test_filename+'_best.csv', n_games=eval_n_samples, exploration=False)\n",
    "\n",
    "                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ccaed8c3f743b1f0f573d1bf9b420e6968f0ad98d33b49a16252e93b5cad05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
